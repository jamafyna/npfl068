\documentclass[12pt, a4paper]{report}
\setlength\textwidth{160mm}
\setlength\textheight{247mm}
\setlength\oddsidemargin{0mm}
\setlength\evensidemargin{15mm}
\setlength\topmargin{0mm}
\setlength\headsep{0mm}
\setlength\headheight{0mm}
%%%%%%%%%%%
\usepackage[czech]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
%\usepackage{ulem}
%\usepackage{tabular}
\usepackage{bbold}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{indentfirst}    %%% zaveď odsazení 1. odstavce
\usepackage{multicol}
% %%%%%%%%%%%%%%
% %sets
% \def\eset{\emptyset}
% \def\seq{\subseteq}
 \def\N{\mathbb{N}}
 \def\Z{\mathbb{Z}}
\def\Q{\mathbb{Q}}
 \def\Lra{\Letfrightarrow}
% %logic
 \def\E{\exists}
 \def\F{\forall}
 \def\imp{\Rightarrow}
 %\def\and{\wedge}
% \def\or{\vee}
 \def\eqv{\Leftrightarrow}
 \def\bimp{\Leftarrow}
\theoremstyle{remark}
\newtheorem{prikl}{Příklad}
\newcommand{\calP}[0]{
\mathcal{P}
}
\newcommand{\seq}[0]{
\subseteq
}

 \def\obrazek#1#2{
% 	\begin{figure}[h!]
 %		\setlength\fboxsep{0pt}
 %		\setlength\fboxrule{1.5pt}
% \begin{centerline}
%\begin{minipage}[0.45]
\begin{center}
 		\includegraphics[width=#2\textwidth]{#1}%[scale=0.5]%width=0.5\textwidth]
\end{center}
%\end{minipage}
 %               \end{centerline}
 %		%\caption{#2}
 %	\end{figure}
 }

\begin{document}
\section*{1. část úkolu - Best Friends}

Ze vzorečku pro počítání PMI $\log_2{\frac{P_2(a,b)}{P(a)P(b)}}$ vidíme, že zda bude hodnota PMI kladná nebo záporná závisí na poměru ${P_2(a,b)}$ a ${P(a)P(b)}$. Pokud ${P(a)P(b)}$ bude větší než ${P_2(a,b)}$ (tj. $a$ i $b$ se vyskytují v textu hodně, zatímco spolu v bigramu se vyskytují málo), tak bude PMI záporná. Vzoreček PMI lze upravit také na  $\log_2{\frac{P_2(a/b)}{P(a)}}$, z čehož můžeme získat ještě jeden pohled --- čím více se vyskytuje $a$ po $b$, tím větší je PMI, tedy pokud bude $P(a/b)$ vyšší než $P(a)$, tak bude PMI kladná, a pokud nižší, tak bude PMI záporná.


\subsection*{Výsledky}

Výsledky pro 20 dvojic s nejvyšší PMI jsou uvedeny v tabulkách, všechny výsledky pak v přiloženém souboru.

Je vidět, že pro bigramy mají nejvyšší PMI ustálená slovní spojení, což koresponduje s výše uvedeným pozorováním, že čím vyšší závislost slova na jeho předchůdci, tím vyšší PMI.
Čeština i angličtina mají srovnatelné hodnoty PMI.

Nejnižší PMI (kolem -8) mají slova, která se k sobě nejspíše dostala chybou (např. \uv{the ,}, \uv{of .}, \uv{, .}, \uv{na .}) nebo vznikla velmi neobvyklým spojením.

Pro distant words vidíme, že mezi prvních 20 s nejvyšší PMI se dostalo několik dvojic, které obsahují dvakrát stejné slovo, což bude způsobeno tím, že se toto slovo vyskytuje v dané vzdálenosti vícekrát. Toto pozorování se shoduje s běžnou praxí, neboť o tématu se zmiňujeme vícekrát v části textu.

Také pro distant words byly některé hodnoty PMI záporné, opět podobně jako v předchozím případě (\uv{2 jsem}, \uv{varieties organs}).
\begin{table}[h!]
\begin{tabular}{lll}
         PMI & první slovo & druhé slovo \\
\toprule
14.169370473805218 & La & Plata \\
14.031866950055282 & Asa & Gray \\
13.362015551747612 & Fritz & Muller \\
13.332869206088096 & worth & while \\
13.262479878196698 & faced & tumbler \\
13.216898843887803 & lowly & organised \\
13.110476784751649 & Malay & Archipelago \\
13.053893256385281 & shoulder & stripe \\
12.914556574776391 & Great & Britain \\
12.847442378917854 & United & States \\
12.525514284030493 & English & carrier \\
12.401816559805589 & specially & endowed \\
12.377363516081047 & Sir & J \\
12.377363516081047 & branched & off \\
12.362015551747612 & mental & qualities \\
12.362015551747612 & de & Candolle \\
12.344942038388671 & Galapagos & Archipelago \\
12.32388042286084 & red & clover \\
12.316927662219076 & self & fertilisation \\
12.25183263399719 & systematic & affinity \\
\end{tabular}
\caption{Prvních 20 párů, angličtina}
\end{table}

\begin{table}[h!]
\begin{tabular}{lll}
         PMI & první slovo & druhé slovo \\
\toprule
14.28895040192613 & Hamburger & SV \\
14.06244187211745 & Los & Angeles \\
13.762881590258543 & Johna & Newcomba \\
13.633598573313575 & Č. & Budějovice \\
13.468967871540775 & série & ATP \\
13.434410649504409 & turnajové & série \\
13.428980853705104 & Tomáš & Ježek \\
13.329922182982436 & Lidové & noviny \\
13.271028493928867 & Lidových & novin \\
13.06244187211745 & veřejného & mínění \\
12.981521876733883 & teplota & minus \\
12.955526668200939 & Ján & Čarnogurský \\
12.955526668200939 & jaderné & zbraně \\
12.897811170344651 & Milan & Máčala \\
12.862877380235263 & lidských & práv \\
12.708433806236165 & společném & státě \\
12.692492262367145 & akciových & společností \\
12.625378066508606 & Pohár & UEFA \\
12.615676665316313 & privatizačních & projektů \\
12.603010253480152 & George & Bushe \\
\end{tabular}
\caption{Prvních 20 párů, čeština}
\end{table}
\begin{table}[h!]
\begin{tabular}{lll}
         PMI & první slovo & druhé slovo \\
\toprule
8.78870856533529 & dried & floated \\
8.66317768325143 & La & Plata \\
8.618783563892977 & floated & dried \\
8.41019694208156 & eastern & Pacific \\
8.38817063575156 & Asa & Gray \\
8.329276946697991 & dried & germinated \\
8.2846660599977 & avicularia & vibracula \\
8.274135392505531 & dried & dried \\
8.187804520745111 & shoulder & stripe \\
8.187804520745111 & stripe & shoulder \\
8.181719758284135 & floated & germinated \\
8.163104080116787 & floated & floated \\
8.136631868755595 & layer & hexagonal \\
8.110636660222651 & survival & fittest \\
8.068816484528025 & dried & days \\
8.04762686269685 & Old & Worlds \\
8.03168531882783 & heath & heath \\
8.03168531882783 & dimorphic & trimorphic \\
7.999128345005662 & geese & webbed \\
7.997295187146707 & clover & clover \\
\end{tabular}
\caption{Prvních 20 distant words, angličtina}
\end{table}

\begin{table}[h!]
\begin{tabular}{lll}
         PMI & první slovo & druhé slovo \\
\toprule
9.826402582133674 & výher & výher \\
9.107211689695445 & žel & žel \\
8.922787118558016 & Bělehrad & Benfica \\
8.871256817917935 & h & teplota \\
8.826402582133674 & 13h & 13h \\
8.797256236474158 & teplota & minus \\
8.797256236474157 & Sandžaku & Sandžaku \\
8.797256236474157 & Hamburger & SV \\
8.797256236474157 & ODÚ & VPN \\
8.756614251976812 & Petrof & Petrof \\
8.659752712724222 & silniční & doprava \\
8.55283750880771 & Atény & Benfica \\
8.546294662940939 & 13h & zataženo \\
8.518280286771343 & 13h & skoro \\
8.475328141586795 & CIA & CIA \\
8.456219318639091 & vychází & h \\
8.449332933053851 & výher & IV \\
8.427306626723853 & 13h & st \\
8.427306626723853 & pořadí & výher \\
8.418744613220428 & Los & Angeles \\
\end{tabular}
\caption{Prvních 20 distant words, čeština}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
%\includegraphics{img-cz-chars.png}
\section*{2. část úkolu - Word Classes}

K určení úplné hierarchie slov, resp. sloučení slov na 15 tříd, jsem použila algoritmus z přednášky. Místo maximalizace celé Mutual Information (MI) jsem použila minimalizaci ztráty MI oproti předchozímu kroku, tedy kostra algoritmu vypadala následovně: 

\begin{itemize}
\item[1.] Inicializace - každému slovu přiřadím svoji třídu
\item[2.] Dokud nedostaneš požadovaný počet tříd (s výskytem alespoň 10x), opakuj:

        \begin{itemize}
        \item[2.1.] Najdi třídy $d$, $e$ (z tříd s výskytem alespoň 10x), pro které je ztráta entropie minimální.
        \item[2.2] Sluč třídy $d$, $e$ do jedné.
        \end{itemize}
\end{itemize}

\subsection*{Implementace}
Hlavní otázkou bylo, jak vhodně reprezentovat třídy, aby bylo nalezení dvou tříd ke sloučení a zároveň jejich sloučení rozumně rychlé. Zjistila jsem, že ideálně by se mi hodila datová struktura, ve které bych měla zahešované/uložené bigramy tříd, která vrací v konstatním čase odpověď, kolik daných bigramů $(c_1,c_2)$ se v textu vyskytuje, a která vrátí v konstantním čase odkaz na všechny bigramy $(c1,*),(*,c1)$ (těch může být až lineárně). Zároveň tato struktura by se měla rozumně rychle aktualizovat (kvůli provádění merge).

Program jsem psala v jazyce Python3. Nechtěla jsem (nebavilo mě) přímo používat přesnou implementaci z přednášek, použila jsem tedy trochu jiné struktury, myšlenky ale zůstávají stejné. V programu jsem zejména využila hashtabulky vracející levé, resp. pravé, sousedy dané třídy a dvakrát CountTable uchovávající počet výskytů daných tříd, resp. bigramů tříd.  

Program se spouští příkazem {\bf python3 ass2\_23\_wordclasses.py TEXT.ptg~1~param}, se třemi parametry, kde TEXT.ptg znamená text, který chceme zpracovat, ve formátu .ptg; 1 označuje, že spouštíme variantu pro slova a ne tagy; param značí počet zbývajících tříd, tedy 1 pro úplnou hierarchii slov a 15 pro sloučení do 15 tříd. 
Výsledek poté vypíše do souboru results-23-*.txt, hvězdička nahrazuje dodané parametry. Kromě výsledné třídy/15 tříd vypisuje také průběh slučování, vč. minimal loss. Výslednou třídu pak ve formátu: {\it slova patřící do této včetně závorek značících postupné slučování --- nový řádek --- slova patřící do této třídy}.

\subsection*{CZ}
Při sloučení na 15 tříd mě zaujala třída skládající se ze spojek, tj. {\it  který, které, aby, ale, že}, obzvlášť že nejprve se sloučily třídy {\it který, které}. Tato třída vyšla hezky ukázkově. Naopak mě překvapilo, že čárka s tečkou zůstaly v samotných jednoprvkových třídách, automaticky bych čekala, že se sloučí, ale zde je možnost, že je rozdílnost dána velkým počátečním písmenem po tečce. Podobným překvapením je samostatná třída se spojkou {\it a}, zatímco spojka {\it i} byla sloučena poměrně brzy. Důvodem může být jiná četnost výskytu. Naopak očekávané mi přijdou pěkná průběžná sloučení tříd {\it byl + jsou, musí + bude, (za, u)+ do}.


\subsection*{EN}

Přijdou mi pěkná a výstižná sloučení tříd {\it may, cannot}, hned jako druhé slučování,  a dále  {\it must + can, is + are, if + when, most + many, would + will}.

Zároveň mi přišlo zajímavé, že slučování tříd poměrně pěkně zachovává slovní druhy, např. při slučování do 15 tříd je třída 2 složena  z podstatných jmen, veškerá přídavná jména jsou ve třídě 6, třída 8 je složena z předložek.

Celkově mi přišlo zajímavé, že slova s velkým počátečním písmenem na začátku mají tendenci slučovat se k sobě, což může být způsobeno téměř jistou tečkou (či jiným méně častým interpunkčním znaménkem) před těmito slovy.

I v anglickém textu zůstaly tečce a čárce jejich vlastní třídy při slučování do 15 tříd, což může být způsobeno tím, že kontext kolem nich je různorodý a v souvislosti s tím, že slova s velkým počátečním písmenem se shlukují často k sobě, a tedy není výhodné ani sloučit tečku a čárku do jedné třídy. Nevhodnost sloučení tečky a čárky potvrzuje i skutečnost, že se do společné třídy dostanou až při posledním slučování, tedy sloučením všech posledních dvou tříd do jedné. Tato skutečnost mě velmi překvapila, protože před výsledkami (a zamyšlením) bych intuitivně čekala, že se velmi brzy sloučí do jedné třídy.

\section*{Tag Classes}
Implementační část byla shodná s úlohou Word classes, akorát místo na slova se algoritmus pouštěl na tagy a místo na prvních 8000 slov se pouštěl na všechna data. Pro angličtinu algoritmus seběhl velmi rychle, neboť angličtina má menší počet různých tagů (anglický text obsahoval pouze 36 různých tagů). Český text obsahoval 677 různých tagů vyskytujících se alespoň pětkrát.

\subsection*{EN}
Očekávané sloučení je PRP\$ a DT, které proběhlo jako 10. merge, neboť přivlastňovací zájmena a DET se vyskytují ve stejném kontextu --- nejčastěji se použije přivlastňovací zájmeno, nebo DET a následuje nejčastěji podstatné jméno nebo přídavné jméno. 


Dále mě zaujala třída ((JJ+JJS)+CD), sloučení JJ+JJS bylo opět očekávané, neboť v kontextu se nejčastěji bude vyskytovat člen před a podstatné jméno za. CD se k nim připojilo, neboť mají opět podobný kontext, v jakém se vyskytují (např. the one/best of them, my best/two friends, atd.).

Další očekávané sloučení je NNS + NN, neboť podstatná jména jednotného a množného čísla se vyskytují v podobném kontextu, navíc angličtina nerozlišuje jiný tvar slovesa, příd. jména apod. dle čísla, s výjimkou třetí osoby u slovesa a přivlastňovacích zájmen. Přišlo mi zajímavé, že jakmile se sloučily třídy NNS + NN, sloučily se třídy VBZ + VBP a navíc minimal loss byla nižší než v předchozích 2 krocích, což svědčí o tom, že sloučení NNS + NN pomohlo. Tento výsledek je zároveň logický, neboť se částečně pomohl sjednotit kontext zleva --- tj. dogs(NNS) are(VBP) hungry vs. child(NN) is(VBZ) small. 

Na rozdíl od zpracování slov ve 2. části úkolu, při slučování tagů se k sobě dostala interpunkční znaménka, v kroce 21 se sloučily třídy \{{: , .}\}.
Naopak mi přišlo divné sloučení tříd NNPS + SYM, a to hned v druhém kroku, zde mi přišlo, že byl výsledek ovlivněn malou diverzitou členů těchto tříd (tag SYM měla pouze pravostranná závorka, NNPS bylo velmi časté u States (z United States)).

\subsection*{CZ}

\end{document}
